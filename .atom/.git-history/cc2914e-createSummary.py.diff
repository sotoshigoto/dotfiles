diff --git a/webCategorize/src/createSummary.py b/webCategorize/src/createSummary.py
index 07bc7ab..2435346 100644
--- a/webCategorize/src/createSummary.py
+++ b/webCategorize/src/createSummary.py
@@ -1,818 +1,820 @@
 #! /usr/bin/python
 # -*- coding: utf-8 -*-
 
 """
 README
 This module"s purpose is summary of Web ans App information after classification.
 """
 
 import pandas as pd
 import numpy as np
 import matplotlib.pyplot as plt
 import functools
 
 from datetime import datetime
 from commonModule import commonModule
 
 
 # インプットデータのディレクトリ
 DATA_DIR_OUT = "/work/CAw/algorithm/yamaguchikuh/WebCategorize/data/output/"
 
 
 class createSummary:
     """興味度算出用クラス"""
 
     def __init__(self):
         self.web_df_list = []
         self.app_df_list = []
         self.web_week_df_list = []
         self.app_week_df_list = []
         self.select_pattern_web_df_list = []
         self.select_pattern_app_df_list = []
-        # self.normalizationOutput_web = 8.5
-        # self.normalizationOutput_app = 5
-        # self.normalizationZeroAndTen_web = 10
-        # self.normalizationZeroAndTen_app = 7
 
         # 計算に利用する事後確率のカテゴリー数（趣味嗜好カテゴリー数に合わせる）
         self.calcCatNum = 165
 
         # 休日の曜日を指定
         self.holiday_list = [5, 6]
 
         # 休日平日&時間帯パターン
         self.pattern_weekdayTerm = {"holiday_0": [1, 0],        # 休日 & 0〜5時
                                     "holiday_6": [1, 6],        # 休日 & 6〜11時
                                     "holiday_12": [1, 12],      # 休日 & 12〜17時
                                     "holiday_18": [1, 18],      # 休日 & 18〜23時
                                     "workday_0": [0, 0],        # 平日 & 0〜5時
                                     "workday_6": [0, 6],        # 平日 & 6〜11時
                                     "workday_12": [0, 12],      # 平日 & 12〜17時
                                     "workday_18": [0, 18],      # 平日 & 18〜23時
                                     }
 
         # 算出対象の休日平日&時間帯パターンを選択
         self.web_select_pattern = ["holiday_0", "holiday_6", "holiday_12", "holiday_18",
                                    "workday_0", "workday_6", "workday_12", "workday_18"]
 
         # 算出対象の休日平日&時間帯パターンを選択
         self.app_select_pattern = ["holiday_0", "holiday_6", "holiday_12", "holiday_18",
                                    "workday_0", "workday_6", "workday_12", "workday_18"]
 
         # 共通処理オブジェクト生成
         self.commonObject = commonModule()
 
     def checkTime(func):
         """処理時間チェック用デコレータ"""
 
         @functools.wraps(func)
         def wrapper(*args, **kwargs):
             start = datetime.today()
             ret = func(*args, **kwargs)
             print("-------------- %s was executed, it took %s sec" % (func.func_name, datetime.now() - start))
             return ret
         return wrapper
 
     def toDateFromEpochTime(self, df):
         """データフレームに日付、時間帯、曜日情報を付加"""
 
         # エポックタイムをタイムスタンプ型へ変化
         df.ix[:, "epoc"] = pd.to_datetime(df.ix[:, "epoc"], unit="ms")
         # 日付を抽出
         df.ix[:, "day"] = df.ix[:, "epoc"].map(lambda x: x.strftime("%Y-%m-%d"))
         # 時間帯を抽出
         df.ix[:, "hour"] = df.ix[:, "epoc"].map(lambda x: x.strftime("%H"))
 
         return df
 
     def getWeekTerm(self, df, day, weekLastday):
         """一週間単位曜日時間帯別にDataFrameを加工する"""
 
         # 一週間枠に丸める
         mask = (df["day"] > weekLastday) & (df["day"] <= day)
         weekDf = df.loc[mask]
 
         return weekDf
 
     def changeHolidayAndFourWeek(self, weekDf):
         """DataFrameに休日判定、時間帯4分割を行い、週単位に統一する"""
 
         # 曜日情報を付与（月:0〜日:6）
         weekDf.ix[:, "weekday"] = weekDf.ix[:, "day"].dt.dayofweek
 
         # 休日判定（休日 = 1、平日 = 0）
         weekDf.ix[weekDf.ix[:, "weekday"].isin(self.holiday_list) == True, "holiday"] = 1
         weekDf.ix[weekDf.ix[:, "weekday"].isin(self.holiday_list) == False, "holiday"] = 0
 
         # 時間帯を4分割（0〜5時, 6〜11時, 12〜17時, 18〜23時）
         weekDf.ix[weekDf.ix[:, "hour"] >= 0, "term"] = 0
         weekDf.ix[weekDf.ix[:, "hour"] >= 6, "term"] = 6
         weekDf.ix[weekDf.ix[:, "hour"] >= 12, "term"] = 12
         weekDf.ix[weekDf.ix[:, "hour"] >= 18, "term"] = 18
 
         return weekDf
 
     def calcPosteriorOfHour(self, weekDf):
         """時間帯毎に事後確率の合計を計算する"""
 
         # 時間帯毎に事後確率を集計
         posterSumData = pd.DataFrame(weekDf.groupby(["day", "cat", "holiday", "term"])["posteriorProb"].sum())
         posterSumData = posterSumData.reset_index()
 
         return posterSumData
 
     def calcBookmarkOfHour(self, weekDf):
         """時間帯毎のbookmarkを集計する"""
 
         # 時間帯毎にbookmark集計
         bookmarkSumWebData = pd.DataFrame(weekDf.groupby(["day", "cat", "holiday", "term"])["bookmark"].sum())
         bookmarkSumWebData = bookmarkSumWebData.reset_index()
 
         return bookmarkSumWebData
 
     def createAppCount(self, weekDf):
         """時間帯毎のAppの利用回数を集計する"""
 
         # 時間帯毎にAppの利用回数を集計
         countSumAppData = pd.DataFrame(weekDf.groupby(["day", "cat", "holiday", "term"])["count"].sum())
         countSumAppData = countSumAppData.reset_index()
 
         return countSumAppData
 
     def mergeDataFrame(self, leftData, rightData, on=None, how=None):
         """データフレームのマージ"""
 
         merged_Df = pd.merge(leftData, rightData, on=on, how=how)
 
         return merged_Df
 
     def calcPercentileFromCount(self, week_df):
         """閲覧回数のパーセンタイル点の計算"""
 
         p_30 = np.percentile(week_df.ix[:, "posteriorProb"], 30, interpolation="linear")  # 30%地点
         p_60 = np.percentile(week_df.ix[:, "posteriorProb"], 60, interpolation="linear")  # 60%地点
         p_90 = np.percentile(week_df.ix[:, "posteriorProb"], 90, interpolation="linear")  # 90%地点
 
         week_df.ix[week_df.ix[:, "posteriorProb"] < p_30, "count_point"] = 1
         week_df.ix[week_df.ix[:, "posteriorProb"] >= p_30, "count_point"] = 2
         week_df.ix[week_df.ix[:, "posteriorProb"] >= p_60, "count_point"] = 3
         week_df.ix[week_df.ix[:, "posteriorProb"] > p_90, "count_point"] = 4
 
         return week_df
 
     def calcPercentileFromBookmark(self, week_df):
         """bookmarkのパーセンタイル点の計算"""
 
         p_30 = np.percentile(week_df.ix[:, "bookRate"], 30, interpolation="linear")  # 30%地点
         p_60 = np.percentile(week_df.ix[:, "bookRate"], 60, interpolation="linear")  # 60%地点
         p_90 = np.percentile(week_df.ix[:, "bookRate"], 90, interpolation="linear")  # 90%地点
 
         week_df.ix[week_df.ix[:, "bookRate"] < p_30, "book_point"] = 1
         week_df.ix[week_df.ix[:, "bookRate"] >= p_30, "book_point"] = 2
         week_df.ix[week_df.ix[:, "bookRate"] >= p_60, "book_point"] = 3
         week_df.ix[week_df.ix[:, "bookRate"] > p_90, "book_point"] = 4
 
         return week_df
 
     def calcPercentileFromWeeklyHour(self, patternedWebDf):
         """曜日別 & 時間帯別のパーセンタイル点の計算"""
 
         p_30 = np.percentile(patternedWebDf.ix[:, "posteriorProb"], 30, interpolation="linear")  # 30%地点
         p_60 = np.percentile(patternedWebDf.ix[:, "posteriorProb"], 60, interpolation="linear")  # 60%地点
         p_90 = np.percentile(patternedWebDf.ix[:, "posteriorProb"], 90, interpolation="linear")  # 90%地点
 
         patternedWebDf.ix[patternedWebDf.ix[:, "posteriorProb"] < p_30, "weekhour_count_point"] = 1
         patternedWebDf.ix[patternedWebDf.ix[:, "posteriorProb"] >= p_30, "weekhour_count_point"] = 2
         patternedWebDf.ix[patternedWebDf.ix[:, "posteriorProb"] >= p_60, "weekhour_count_point"] = 3
         patternedWebDf.ix[patternedWebDf.ix[:, "posteriorProb"] > p_90, "weekhour_count_point"] = 4
         patternedWebDf = patternedWebDf.reset_index(drop=True)
 
         return patternedWebDf
 
     def selectWeeklyHourWebPattern(self, weekHourDf):
         """指定したWebの休日平日&時間帯別のパターンのデータを抽出"""
 
         pattern_count = 0
         # 選択したパターンのデータを抽出
         for key in self.web_select_pattern:
 
             holidayTermWebDf = weekHourDf[(weekHourDf.holiday == self.pattern_weekdayTerm[key][0]) &
                                           (weekHourDf.term == self.pattern_weekdayTerm[key][1])]
 
             if holidayTermWebDf.empty == False:
                 self.select_pattern_web_df_list.append(holidayTermWebDf)
                 pattern_count += 1
 
         patternedWebDf = pd.concat(self.select_pattern_web_df_list)
         patternedWebDf = patternedWebDf.reset_index(drop=True)
 
         return patternedWebDf, pattern_count
 
     def selectWeeklyHourAppPattern(self, weekHourDf):
         """指定したAppの休日平日&時間帯別のパターンのデータを抽出"""
 
         # 選択したパターンのデータを抽出
         for key in self.app_select_pattern:
 
             holidayTermAppDf = weekHourDf[(weekHourDf.holiday == self.pattern_weekdayTerm[key][0]) &
                                           (weekHourDf.term == self.pattern_weekdayTerm[key][1])]
             self.select_pattern_app_df_list.append(holidayTermAppDf)
 
         patternedAppDf = pd.concat(self.select_pattern_app_df_list)
         patternedAppDf = patternedAppDf.reset_index(drop=True)
 
         return patternedAppDf, len(self.app_select_pattern)
 
     def createHistgram(self, df):
         """ヒストグラム作成"""
 
         df["bookmark"].hist()
         plt.show()
 
         return
 
     @checkTime
     def createMasterWebSummary(self, now_datetime):
         """Web情報のマスターサマリーを作成"""
 
         print "--------- Start create Master Web Summary"
 
         # インプットファイルの読み込み
         naive_web_data = self.commonObject.readWebNaiveBayes(now_datetime)
         sensor_web_data = self.commonObject.readWebSensorInformation(now_datetime)
 
         del naive_web_data["Unnamed: 0"]
         del sensor_web_data["Unnamed: 0"]
 
         # DataFrameのマージ前にkeyとなるカラム名を揃える
         naive_web_data.columns = ["url", "cat", "posteriorProb"]
 
+        # レコード絞り込み処理の前に事後確率が最小値のカテゴリーを削除する
+        posterior_df = naive_web_data.groupby(["url"])["posteriorProb"].min()
+        posterior_dict = posterior_df.to_dict()
+        naive_web_data['min_posterior'] = naive_web_data["url"].map(lambda x: posterior_dict[x])
+        naive_web_data = naive_web_data.ix[(naive_web_data["posteriorProb"] == naive_web_data["min_posterior"]) == False, :]
+        del naive_web_data["min_posterior"]
+
         # ナイーブベイズDFのレコード数を絞り込む（性能懸念のため最大165レコードとする）
         naive_web_data = naive_web_data.sort(["url", "posteriorProb"], ascending=False)
         naive_web_data = naive_web_data.groupby(["url"]).head(self.calcCatNum)
 
         # ナイーブベイズDFとセンサーデータDFをマージ
         masterWebDf = self.mergeDataFrame(sensor_web_data, naive_web_data, "url", "inner")
 
         # 欠損値除去
         masterWebDf = masterWebDf.dropna()
 
         # タイムスタンプ変換
         masterWebDf = self.toDateFromEpochTime(masterWebDf)
         masterWebDf = masterWebDf.sort(columns="epoc")
 
         # 異常値があれば削除(1970-01-01のデータが観測されたために削除)
         masterWebDf = masterWebDf.ix[masterWebDf.ix[:, "day"].isin(["1970-01-01"]) == False, :]
 
         # データ取得日時カラムを除去
         del masterWebDf["get_data_epoc"]
 
         # カラム名を修正
         masterWebDf.columns = ["url", "date", "bookmark", "count", "cat", "posteriorProb", "day", "hour"]
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(masterWebDf, "webMasterSummary", "web_master_summary", now_datetime)
 
         return masterWebDf
 
     @checkTime
     def createMasterAppSummary(self, now_datetime):
         """App情報のマスターサマリーを作成"""
 
         print "--------- Start create Master App Summary"
 
         # インプットファイルの読み込み
         naive_app_data = self.commonObject.readAppNaiveBayes(now_datetime)
         sensor_app_data = self.commonObject.readAppSensorInformation(now_datetime)
 
         del naive_app_data["Unnamed: 0"]
         del sensor_app_data["Unnamed: 0"]
 
         # DataFrameのマージ前にkeyとなるカラム名を揃える
         naive_app_data.columns = ["package", "cat", "posteriorProb"]
 
+        # レコード絞り込み処理の前に事後確率が最小値のカテゴリーを削除する
+        posterior_df = naive_app_data.groupby(["package"])["posteriorProb"].min()
+        posterior_dict = posterior_df.to_dict()
+        naive_app_data['min_posterior'] = naive_app_data["package"].map(lambda x: posterior_dict[x])
+        naive_web_data = naive_app_data.ix[(naive_app_data["posteriorProb"] == naive_app_data["min_posterior"]) == False, :]
+        del naive_web_data["min_posterior"]
+
         # ナイーブベイズDFのレコード数を絞り込む（性能懸念のため最大165レコードとする）
         naive_app_data = naive_app_data.sort(["package", "posteriorProb"], ascending=False)
         naive_app_data = naive_app_data.groupby(["package"]).head(self.calcCatNum)
 
         # ナイーブベイズDFとセンサーデータDFをマージ
         masterAppDf = self.mergeDataFrame(sensor_app_data, naive_app_data, "package", "inner")
 
         # 異常値があれば削除(1970-01-01のデータが観測されたために削除)
         masterAppDf = masterAppDf.ix[masterAppDf.ix[:, "day"].isin(["1970-01-01"]) == False, :]
 
         # 欠損値除去
         masterAppDf = masterAppDf.dropna()
 
         # カラム名を修正
         masterAppDf.columns = ["package", "day", "hour", "count", "cat", "posteriorProb"]
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(masterAppDf, "appMasterSummary", "app_master_summary", now_datetime)
 
         return masterAppDf
 
     @checkTime
     def webWeekdateHourSummaryMain(self, now_datetime):
         """Web情報の一週間統計範囲、曜日単位、時間帯単位で丸めたサマライズモジュール"""
 
         print "--------- Start calculation Web Summary WeekHour"
 
         # インプットファイルの読み込み
         masterSumWebData = self.commonObject.readMasterWebSummaryInformation(now_datetime)
         masterSumWebData.ix[:, "day"] = pd.to_datetime(masterSumWebData.ix[:, "day"])
 
         del masterSumWebData["Unnamed: 0"]
         masterSumWebData = masterSumWebData.sort(columns="day")
 
         # 日付リストを作成
         day_list = sorted(list(set(masterSumWebData["day"])))
 
         for day in day_list:
 
             # 一週間前の日付を取得
             weekLastWebDate = day - pd.offsets.Day(7)
 
             # 一週間の統計範囲でのDataFrameを抽出
             weekWebDf = self.getWeekTerm(masterSumWebData, day, weekLastWebDate)
 
             # 一週間単位で計算するために日付を統一
             weekWebDf.ix[:, "day"] = day
 
             # 休日平日/時間帯毎にデータを整形
             weekWebDf = self.changeHolidayAndFourWeek(weekWebDf)
 
             # 時間帯毎の事後確率を合算
             posterSumWebData = self.calcPosteriorOfHour(weekWebDf)
 
             # 時間帯毎のbookmark数を合算
             bookmarkSumWebData = self.calcBookmarkOfHour(weekWebDf)
 
             # 時間帯毎の事後確率合計と時間帯毎のbookmark合計をマージ
             hourSumWebData = self.mergeDataFrame(posterSumWebData, bookmarkSumWebData,
                                                  ["day", "cat", "holiday", "term"], "inner")
 
             # 集計結果をDFへ結合
             self.web_df_list.append(hourSumWebData)
 
         # Web集計結果にDF_listを結合
         if len(self.web_df_list) > 0:
             webSumDf = pd.concat(self.web_df_list)
             webSumDf = webSumDf.reset_index(drop=True)
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(webSumDf, "webWeekHourSummary", "web_week_hour_summary", now_datetime)
 
         print "Finish!"
 
         return webSumDf
 
     @checkTime
     def appWeekdateHourSummaryMain(self, now_datetime):
         """アプリ情報の一週間統計範囲、曜日単位、時間帯単位で丸めたサマライズモジュール"""
 
         print "--------- Start calculation App Summary WeekHour"
 
         # インプットファイルの読み込み
         masterSumAppData = self.commonObject.readMasterAppSummaryInformation(now_datetime)
         masterSumAppData.ix[:, "day"] = pd.to_datetime(masterSumAppData.ix[:, "day"])
 
         masterSumAppData = masterSumAppData.sort(columns="day")
         del masterSumAppData["Unnamed: 0"]
 
         # 日付リストを作成
         day_list = sorted(list(set(masterSumAppData["day"])))
 
         for day in day_list:
 
             # 一週間前の日付を取得
             weekLastAppDate = day - pd.offsets.Day(7)
 
             # 一週間単位のDataFrameを抽出
             weekAppDf = self.getWeekTerm(masterSumAppData, day, weekLastAppDate)
 
             # 一週間単位で計算するために日付を統一
             weekAppDf.ix[:, "day"] = day
 
             # 休日平日/時間帯毎にデータを整形
             weekAppDf = self.changeHolidayAndFourWeek(weekAppDf)
 
             # 時間帯毎の事後確率を合算
             posterSumAppData = self.calcPosteriorOfHour(weekAppDf)
 
             # 時間帯毎の利用数を合算
             countSumAppData = self.createAppCount(weekAppDf)
 
             # 時間帯毎の事後確率合計と時間帯毎の利用回数合計をマージ
             hourSumAppData = self.mergeDataFrame(posterSumAppData, countSumAppData,
                                                  ["day", "cat", "holiday", "term"], "inner")
 
             # 集計結果をDFへ結合
             self.app_df_list.append(hourSumAppData)
 
         # App集計結果にSDF_listを結合
         if len(self.app_df_list) > 0:
             appSumDf = pd.concat(self.app_df_list)
             appSumDf = appSumDf.reset_index()
 
         del appSumDf["index"]
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(appSumDf, "appWeekHourSummary", "app_week_hour_summary", now_datetime)
 
         print "Finish!"
 
         return appSumDf
 
     @checkTime
     def weeklyWebSummaryMain(self, now_datetime):
         """Web情報を一週間統計範囲で計算するモジュール"""
 
         print "--------- Start calculation Web Summary Week"
 
         # インプットファイルの読み込み
         weekhourSumWebData = self.commonObject.readWeekHourWebSummaryInformation(now_datetime)
         weekhourSumWebData.ix[:, "day"] = pd.to_datetime(weekhourSumWebData.ix[:, "day"])
 
         # 週単位でカテゴリーの事後確率を集計
         countWeekWebDf = pd.DataFrame(weekhourSumWebData.groupby(["day", "cat"])["posteriorProb"].sum())
         countWeekWebDf = countWeekWebDf.reset_index()
 
         # 週単位でカテゴリー毎のブックマーク合計値を集計
         sumBookmarkWeekWebDf = weekhourSumWebData.groupby(["day", "cat"])["bookmark"].sum()
         sumBookmarkWeekWebDf = sumBookmarkWeekWebDf.reset_index()
 
         # 週単位でカテゴリー毎のレコード数を集計
         countBookmarkWeekWebDf = pd.DataFrame(weekhourSumWebData.groupby(["day", "cat"]).size())
         countBookmarkWeekWebDf = countBookmarkWeekWebDf.reset_index()
         countBookmarkWeekWebDf.columns = ["day", "cat", "bookmarkCount"]
 
         # ブックマーク率を算出
         sumBookmarkWeekWebDf.ix[:, "bookRate"] = np.float64(sumBookmarkWeekWebDf.ix[:, "bookmark"]) * countWeekWebDf.ix[:, "posteriorProb"]
         sumBookmarkWeekWebDf.ix[:, "bookRate"] = sumBookmarkWeekWebDf.ix[:, "bookRate"] / countBookmarkWeekWebDf.ix[:, "bookmarkCount"]
 
         # 閲覧回数とブックマークをマージ
         sumWeekWebDf = self.mergeDataFrame(countWeekWebDf, sumBookmarkWeekWebDf, ["day", "cat"], "inner")
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(sumWeekWebDf, "webWeekSummary", "web_week_summary", now_datetime)
 
         print "Finish!"
 
         return sumWeekWebDf
 
     @checkTime
     def weeklyAppSummaryMain(self, now_datetime):
         """App情報を一週間単位で丸めたサマライズモジュール"""
 
         print "--------- Start calculation App Summary Week"
 
         # インプットファイルの読み込み
         weekhourSumAppData = self.commonObject.readWeekHourAppSummaryInformation(now_datetime)
         weekhourSumAppData.ix[:, "day"] = pd.to_datetime(weekhourSumAppData.ix[:, "day"])
         del weekhourSumAppData["Unnamed: 0"]
 
         # 週単位でカテゴリー毎の事後確率を合算
         countWeekAppDf = pd.DataFrame(weekhourSumAppData.groupby(["day", "cat"])["posteriorProb"].sum())
         countWeekAppDf = countWeekAppDf.reset_index()
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(countWeekAppDf, "appWeekSummary", "app_week_summary", now_datetime)
 
         print "Finish!"
 
         return countWeekAppDf
 
     @checkTime
     def webCalcWeight(self, now_datetime):
         """Webの重み計算"""
 
         week_df_list = []
 
         # 1週間単位集計のインプットファイルの読み込み
         weekSumWebData = self.commonObject.readWeekWebSummaryInformation(now_datetime)
         weekSumWebData.ix[:, "day"] = pd.to_datetime(weekSumWebData.ix[:, "day"])
 
         # 1週間 & 時間帯単位集計のインプットファイルの読み込み
         weekTimeSumWebData = self.commonObject.readWeekHourWebSummaryInformation(now_datetime)
         weekTimeSumWebData.ix[:, "day"] = pd.to_datetime(weekTimeSumWebData.ix[:, "day"])
 
         # 列番号0のUnnamedを削除
         del weekSumWebData["Unnamed: 0"]
         del weekTimeSumWebData["Unnamed: 0"]
 
         # 日付のリスト作成
         dayly = sorted(list(set(weekSumWebData["day"])))
         weekSumWebData = weekSumWebData.reset_index(drop=True)
 
         for day in dayly:
 
             # 計算対象のDataFrameを抽出
             week_web_df = weekSumWebData.ix[weekSumWebData.ix[:, "day"] == day]
             weekTime_web_df = weekTimeSumWebData.ix[weekTimeSumWebData.ix[:, "day"] == day]
 
             # 閲覧回数パーセンタイルの計算
             calcedCountWeekWebDf = self.calcPercentileFromCount(week_web_df)
 
             # bookmark率パーセンタイルの計算
             calcedBookWeekWebDf = self.calcPercentileFromBookmark(calcedCountWeekWebDf)
             del calcedBookWeekWebDf["bookmark"]
             del calcedBookWeekWebDf["bookRate"]
 
             # 曜日 & 時間帯のパターンを選択
             selectedWeekHourWebDf, pattern_length = self.selectWeeklyHourWebPattern(weekTime_web_df)
 
             # 平日休日 & 時間帯単位のパーセンタイルの計算
             calcedWeeklyHourWebDf = self.calcPercentileFromWeeklyHour(selectedWeekHourWebDf)
             calcedWeeklyHourWebDf = pd.DataFrame(calcedWeeklyHourWebDf.groupby(["day", "cat"])
                                                  ["weekhour_count_point"].sum() / pattern_length)
             calcedWeeklyHourWebDf = calcedWeeklyHourWebDf.reset_index()
 
             # DataFrameマージ
             calcedAllWebData = self.mergeDataFrame(calcedBookWeekWebDf, calcedWeeklyHourWebDf, ["day", "cat"], "inner")
+
             # 各パーセンタイルの値を合算
             calcedAllWebData["sum_point"] = calcedAllWebData.ix[:, "count_point"] \
                 + calcedAllWebData.ix[:, "book_point"] + calcedAllWebData.ix[:, "weekhour_count_point"]
 
-            # # 0〜10の値に収まるように計算
-            # calcedAllWebData.ix[:, "sum_point"] = \
-            #     calcedAllWebData.ix[:, "sum_point"].map(lambda x: min(max(0, (x - self.normalizationOutput_web) * \
-            #                                             (10 / (self.normalizationZeroAndTen_web - self.normalizationOutput_web))), 10))
-            # point_list = calcedAllWebData["sum_point"].tolist()
-            # # 全ての出力値が同じであれば0に変換
-            # if np.var(point_list) == 0:
-            #     calcedAllWebData["sum_point"] = 0
-
             # 0〜10の範囲に値が収まる様に計算 : x' = (x - min) * (10 / (max - min))
             min_num = min(calcedAllWebData["sum_point"])
             max_num = max(calcedAllWebData["sum_point"])
             diff_max_min = max_num - min_num
             if diff_max_min != 0:
                 calcedAllWebData.ix[:, "sum_point"] = calcedAllWebData["sum_point"].map(lambda x: float(x - min_num) * float(10 / (diff_max_min)))
             else:
                 calcedAllWebData.ix[:, "sum_point"] = 0
 
             week_df_list.append(calcedAllWebData)
 
         if len(week_df_list) > 0:
             # DataFrameを結合
             sumWeekWebDf = pd.DataFrame()
             sumWeekWebDf = pd.concat(week_df_list)
             sumWeekWebDf = sumWeekWebDf.reset_index(drop=True)
 
         # 忘却係数の計算
         resultWebDf = self.calcForget(sumWeekWebDf, dayly)
 
         # 不要なカラムを削除
         del resultWebDf["posteriorProb"]
         del resultWebDf["count_point"]
         del resultWebDf["book_point"]
         del resultWebDf["weekhour_count_point"]
         del resultWebDf["sum_point"]
 
         resultWebDf = resultWebDf.reset_index()
         del resultWebDf["index"]
         self.commonObject.writeCsv(resultWebDf, "webResult", "web_result", now_datetime)
 
         return resultWebDf
 
     @checkTime
     def appCalcWeight(self, now_datetime):
         """Appの重み計算"""
 
         week_df_list = []
 
         # 1週間単位集計のインプットファイルの読み込み
         weekSumAppData = self.commonObject.readWeekAppSummaryInformation(now_datetime)
         weekSumAppData.ix[:, "day"] = pd.to_datetime(weekSumAppData.ix[:, "day"])
 
         # 1週間 & 時間帯単位集計のインプットファイルの読み込み
         weekTimeSumAppData = self.commonObject.readWeekHourAppSummaryInformation(now_datetime)
         weekTimeSumAppData.ix[:, "day"] = pd.to_datetime(weekTimeSumAppData.ix[:, "day"])
 
         # 列番号0のUnnamedを削除
         del weekSumAppData["Unnamed: 0"]
         del weekTimeSumAppData["Unnamed: 0"]
 
         # 日付のリスト作成
         dayly = sorted(list(set(weekSumAppData["day"])))
         weekSumAppData = weekSumAppData.reset_index(drop=True)
 
         for day in dayly:
 
             # 計算対象のDataFrameを抽出
             week_app_df = weekSumAppData.ix[weekSumAppData.ix[:, "day"] == day]
             weekTime_app_df = weekTimeSumAppData.ix[weekTimeSumAppData.ix[:, "day"] == day]
             # 利用回数パーセンタイルの計算
             calcedCountWeekAppDf = self.calcPercentileFromCount(week_app_df)
             # 休日平日&時間帯のパターンを選択
             selectedWeekHourAppDf, pattern_length = self.selectWeeklyHourAppPattern(weekTime_app_df)
             # 平日休日 & 時間帯単位のパーセンタイルの計算
             calcedWeeklyHourAppDf = self.calcPercentileFromWeeklyHour(selectedWeekHourAppDf)
             calcedWeeklyHourAppDf = pd.DataFrame(calcedWeeklyHourAppDf.groupby(["day", "cat"])["weekhour_count_point"].sum() / pattern_length)
             calcedWeeklyHourAppDf = calcedWeeklyHourAppDf.reset_index()
 
             # DataFrameマージ
             calcedAllAppData = self.mergeDataFrame(calcedCountWeekAppDf, calcedWeeklyHourAppDf, ["day", "cat"], "inner")
             # 各パーセンタイルの値を合算
             calcedAllAppData["sum_point"] = calcedAllAppData.ix[:, "count_point"] + calcedAllAppData.ix[:, "weekhour_count_point"]
 
             # 0〜10の値に収まるように計算
             calcedAllAppData.ix[:, "sum_point"] = \
-                calcedAllAppData.ix[:, "sum_point"].map(lambda x: (max(0, x - self.normalizationOutput_app) * 10) / \
-                                                        (self.normalizationZeroAndTen_app - self.normalizationOutput_app))
+                calcedAllAppData.ix[:, "sum_point"].map(lambda x: (max(0, x - self.normalizationOutput_app) * 10) \
+                                                        / (self.normalizationZeroAndTen_app - self.normalizationOutput_app))
 
             week_df_list.append(calcedAllAppData)
 
         if len(week_df_list) > 0:
             # DataFrameを結合
             sumWeekAppDf = pd.DataFrame()
             sumWeekAppDf = pd.concat(week_df_list)
             sumWeekAppDf = sumWeekAppDf.reset_index(drop=True)
 
         # 忘却係数の計算
         resultAppDf = self.calcForget(sumWeekAppDf, dayly)
 
         # 不要なカラムを削除
         del resultAppDf["posteriorProb"]
         del resultAppDf["count_point"]
         del resultAppDf["weekhour_count_point"]
         del resultAppDf["sum_point"]
 
         # indexの振り直し
         resultAppDf = resultAppDf.reset_index()
         del resultAppDf["index"]
 
         # csvへ結果を書き込み
         self.commonObject.writeCsv(resultAppDf, "appResult", "app_result", now_datetime)
 
         return resultAppDf
 
     @checkTime
     def calcForget(self, df, dayly):
         """忘却係数の計算"""
 
         forgetCoefficient = 0.8     # 忘却係数
         week_forget_df_list = []
 
         # 週単位で忘却係数計算
         for i, day in enumerate(dayly):
 
             # 初回日の計算
             if i == 0:
                 week_df = df.ix[df.ix[:, "day"] == day]
                 week_df["hobby_point"] = week_df.ix[:, "sum_point"]
 
                 # 次の週での計算に利用するために前回週変数へ格納する
                 last_week_df = week_df[["cat", "hobby_point"]]
 
                 # 算出した興味度の高い順にソートし、リストへ格納する
                 week_df = week_df.sort("hobby_point", ascending=False)
                 week_forget_df_list.append(week_df)
 
             # 初回以降の計算
             else:
                 week_df = df.ix[df.ix[:, "day"] == day]
 
                 # 今回の週と前回の週をマージする
                 week_df = self.mergeDataFrame(week_df, last_week_df, ["cat"], "inner")
 
                 # 忘却係数を利用した計算
                 week_df["hobby_point"] = week_df.ix[:, "sum_point"] * (1 - forgetCoefficient) + week_df.ix[:, "hobby_point"] * forgetCoefficient
 
                 # 次の週での計算に利用するために前回週変数へ格納する
                 last_week_df = week_df[["cat", "hobby_point"]]
 
                 # 算出した興味度の高い順にソートし、リストへ格納する
                 week_df = week_df.sort("hobby_point", ascending=False)
                 week_forget_df_list.append(week_df)
 
         if len(week_forget_df_list) > 0:
             # DataFrameを結合
             resultDf = pd.DataFrame()
             resultDf = pd.concat(week_forget_df_list)
             resultDf = resultDf.reset_index(drop=True)
 
         return resultDf
 
 
 def test_toDataFromEpochTime():
     """エポックタイム日付変換テスト"""
 
     epock = 1445244721440
     obj = createSummary()
     dateSet = obj.toDateFromEpochTime(epock)
 
     assert dateSet[0] == "2015-10-19"
     assert dateSet[1] == "09"
 
     return "Test OK!"
 
 
 def test_createMasterWebSummary():
     """createMasterWebSummaryのテスト"""
 
-    now_datetime = "20151203-201053"
+    now_datetime = "20160215-195545"
     obj = createSummary()
     resultDf = obj.createMasterWebSummary(now_datetime)
 
-    assert resultDf > 0
+    assert len(resultDf) > 0
 
     return "Test OK!"
 
 
 def test_createMasterAppSummary():
     """createMasterAppSummaryのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.createMasterAppSummary(now_datetime)
 
     assert resultDf > 0
 
     return "Test OK!"
 
 
 def test_webWeekdateHourSummaryMain():
     """webWeekdateHourSummaryMainのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.webWeekdateHourSummaryMain(now_datetime)
 
     assert resultDf > 0
 
     return "Test OK!"
 
 
 def test_appWeekdateHourSummaryMain():
     """appWeekdateHourSummaryMainのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.appWeekdateHourSummaryMain(now_datetime)
 
     assert resultDf > 0
 
     return "Test OK!"
 
 
 def test_weeklyWebSummaryMain():
     """weeklyWebSummaryMainのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.weeklyWebSummaryMain(now_datetime)
 
     assert resultDf > 0
 
     return "Test OK!"
 
 
 def test_weeklyAppSummaryMain():
     """weeklyWebSummaryMainのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.weeklyAppSummaryMain(now_datetime)
 
     assert resultDf > 0
 
     return "Test OK!"
 
 
 def test_webCalcWeight():
     """webCalcWeightのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.webCalcWeight(now_datetime)
 
     assert resultDf is not False
 
     return "Test OK!"
 
 
 def test_appCalcWeight():
     """appCalcWeightのテスト"""
 
     now_datetime = "20151203-201053"
     obj = createSummary()
     resultDf = obj.appCalcWeight(now_datetime)
     print(resultDf)
     assert resultDf is not False
 
     return "Test OK!"
 
 
 if __name__ == "__main__":
 
     # print test_toDataFromEpochTime()
-    # print test_createMasterWebSummary()
+    print test_createMasterWebSummary()
     # print test_createMasterAppSummary()
     # print test_webWeekdateHourSummaryMain()
     # print test_appWeekdateHourSummaryMain()
     # print test_weeklyWebSummaryMain()
     # print test_weeklyAppSummaryMain()
-    print test_webCalcWeight()
+    # print test_webCalcWeight()
     # print test_appCalcWeight()
